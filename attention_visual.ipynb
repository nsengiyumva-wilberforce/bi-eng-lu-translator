{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2579edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import Transformer\n",
    "from config import get_config, get_weights_file_path\n",
    "from train import get_model, get_ds, greedy_decode\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ce12c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f'Using device {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9605c623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Columns: ['English', 'Luganda']\n",
      "Max length of the source sentence: 45\n",
      "Max length of the target sentence: 37\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Load the pretrained weights\u001b[39;00m\n\u001b[32m      6\u001b[39m model_filename = get_weights_file_path(config, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m18\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m state = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m model.load_state_dict(state[\u001b[33m'\u001b[39m\u001b[33mmodel_state_dict\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nseng\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:1516\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1514\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[32m   1515\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1516\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1517\u001b[39m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1518\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1519\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_weights_only_unpickler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1520\u001b[39m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1521\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1523\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1524\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nseng\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:2114\u001b[39m, in \u001b[36m_load\u001b[39m\u001b[34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[39m\n\u001b[32m   2112\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[32m   2113\u001b[39m _serialization_tls.map_location = map_location\n\u001b[32m-> \u001b[39m\u001b[32m2114\u001b[39m result = \u001b[43munpickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2115\u001b[39m _serialization_tls.map_location = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2117\u001b[39m torch._utils._validate_loaded_sparse_tensors()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nseng\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_weights_only_unpickler.py:532\u001b[39m, in \u001b[36mUnpickler.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    525\u001b[39m         \u001b[38;5;28mtype\u001b[39m(pid) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m\n\u001b[32m    526\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pid) > \u001b[32m0\u001b[39m\n\u001b[32m    527\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m torch.serialization._maybe_decode_ascii(pid[\u001b[32m0\u001b[39m]) != \u001b[33m\"\u001b[39m\u001b[33mstorage\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    528\u001b[39m     ):\n\u001b[32m    529\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\n\u001b[32m    530\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOnly persistent_load of storage is allowed, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpid[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    531\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m     \u001b[38;5;28mself\u001b[39m.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpersistent_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key[\u001b[32m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [BINGET[\u001b[32m0\u001b[39m], LONG_BINGET[\u001b[32m0\u001b[39m]]:\n\u001b[32m    534\u001b[39m     idx = (read(\u001b[32m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m key[\u001b[32m0\u001b[39m] == BINGET[\u001b[32m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m unpack(\u001b[33m\"\u001b[39m\u001b[33m<I\u001b[39m\u001b[33m\"\u001b[39m, read(\u001b[32m4\u001b[39m)))[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nseng\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:2078\u001b[39m, in \u001b[36m_load.<locals>.persistent_load\u001b[39m\u001b[34m(saved_id)\u001b[39m\n\u001b[32m   2076\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2077\u001b[39m     nbytes = numel * torch._utils._element_size(dtype)\n\u001b[32m-> \u001b[39m\u001b[32m2078\u001b[39m     typed_storage = \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2079\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2082\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nseng\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:2044\u001b[39m, in \u001b[36m_load.<locals>.load_tensor\u001b[39m\u001b[34m(dtype, numel, key, location)\u001b[39m\n\u001b[32m   2040\u001b[39m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[32m   2041\u001b[39m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[32m   2043\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch._guards.detect_fake_mode(\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2044\u001b[39m     wrap_storage = \u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2045\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2046\u001b[39m     storage._fake_device = location\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nseng\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:698\u001b[39m, in \u001b[36mdefault_restore_location\u001b[39m\u001b[34m(storage, location)\u001b[39m\n\u001b[32m    678\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    679\u001b[39m \u001b[33;03mRestores `storage` using a deserializer function registered for the `location`.\u001b[39;00m\n\u001b[32m    680\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    695\u001b[39m \u001b[33;03m       all matching ones return `None`.\u001b[39;00m\n\u001b[32m    696\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    697\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[32m--> \u001b[39m\u001b[32m698\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    699\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    700\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nseng\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:636\u001b[39m, in \u001b[36m_deserialize\u001b[39m\u001b[34m(backend_name, obj, location)\u001b[39m\n\u001b[32m    634\u001b[39m     backend_name = torch._C._get_privateuse1_backend_name()\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m location.startswith(backend_name):\n\u001b[32m--> \u001b[39m\u001b[32m636\u001b[39m     device = \u001b[43m_validate_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    637\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj.to(device=device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nseng\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:605\u001b[39m, in \u001b[36m_validate_device\u001b[39m\u001b[34m(location, backend_name)\u001b[39m\n\u001b[32m    603\u001b[39m     device_index = device.index \u001b[38;5;28;01mif\u001b[39;00m device.index \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    604\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[33m\"\u001b[39m\u001b[33mis_available\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m device_module.is_available():\n\u001b[32m--> \u001b[39m\u001b[32m605\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    606\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttempting to deserialize object on a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name.upper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    607\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdevice but torch.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.is_available() is False. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    608\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIf you are running on a CPU-only machine, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m\u001b[33m) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    610\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mto map your storages to the CPU.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    611\u001b[39m     )\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[33m\"\u001b[39m\u001b[33mdevice_count\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    613\u001b[39m     device_count = device_module.device_count()\n",
      "\u001b[31mRuntimeError\u001b[39m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "config = get_config()\n",
    "train_dataloader, val_dataloader, vocab_src, vocab_tgt = get_ds(config)\n",
    "model = get_model(config, vocab_src.get_vocab_size(), vocab_tgt.get_vocab_size()).to(device)\n",
    "\n",
    "# Load the pretrained weights\n",
    "model_filename = get_weights_file_path(config, f\"18\")\n",
    "state = torch.load(\"/content/drive/MyDrive/tmodel_18.pt\")\n",
    "model.load_state_dict(state['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4818cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_next_batch():\n",
    "    batch = next(iter(val_dataloader))\n",
    "    encoder_input = batch['encoder_input'].to(device)\n",
    "    encoder_mask = batch['encoder_mask'].to(device)\n",
    "    decoder_input = batch['decoder_input'].to(device)\n",
    "    decoder_mask = batch['decoder_mask'].to(device)\n",
    "\n",
    "    encoder_input_tokens = [vocab_src.id_to_token(idx) for idx in encoder_input[0].cpu().numpy()]\n",
    "    decoder_input_tokens = [vocab_tgt.id_to_token(idx) for idx in decoder_input[0].cpu().numpy()]\n",
    "\n",
    "    model_out = greedy_decode(model, encoder_input, encoder_mask, vocab_src, vocab_tgt, config['seq_len'], device)\n",
    "\n",
    "    return batch, encoder_input_tokens, decoder_input_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cc4dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mtx2df(m, max_row, max_col, row_tokens, col_tokens):\n",
    "    return pd.DataFrame(\n",
    "        [\n",
    "            (\n",
    "                r,\n",
    "                c,\n",
    "                float(m[r, c]),\n",
    "                \"%.3d %s\" % (r, row_tokens[r] if len(row_tokens) > r else \"<blank>\"),\n",
    "                \"%.3d %s\" % (c, col_tokens[c] if len(col_tokens) > c else \"<blank>\"),\n",
    "            )\n",
    "            for r in range(m.shape[0])\n",
    "            for c in range(m.shape[1])\n",
    "            if r < max_row and c < max_col\n",
    "        ],\n",
    "        columns=[\"row\", \"column\", \"value\", \"row_token\", \"col_token\"],\n",
    "    )\n",
    "\n",
    "def get_attn_map(attn_type: str, layer: int, head: int):\n",
    "    if attn_type == \"encoder\":\n",
    "        attn = model.encoder.layers[layer].self_attention_block.attention_scores\n",
    "    elif attn_type == \"decoder\":\n",
    "        attn = model.decoder.layers[layer].self_attention_block.attention_scores\n",
    "    elif attn_type == \"encoder-decoder\":\n",
    "        attn = model.decoder.layers[layer].cross_attention_block.attention_scores\n",
    "    return attn[0, head].data\n",
    "\n",
    "def attn_map(attn_type, layer, head, row_tokens, col_tokens, max_sentence_len):\n",
    "    df = mtx2df(\n",
    "        get_attn_map(attn_type, layer, head),\n",
    "        max_sentence_len,\n",
    "        max_sentence_len,\n",
    "        row_tokens,\n",
    "        col_tokens,\n",
    "    )\n",
    "    return (\n",
    "        alt.Chart(data=df)\n",
    "        .mark_rect()\n",
    "        .encode(\n",
    "            x=alt.X(\"col_token\", axis=alt.Axis(title=\"\")),\n",
    "            y=alt.Y(\"row_token\", axis=alt.Axis(title=\"\")),\n",
    "            color=\"value\",\n",
    "            tooltip=[\"row\", \"column\", \"value\", \"row_token\", \"col_token\"],\n",
    "        )\n",
    "        #.title(f\"Layer {layer} Head {head}\")\n",
    "        .properties(height=400, width=400, title=f\"Layer {layer} Head {head}\")\n",
    "        .interactive()\n",
    "    )\n",
    "\n",
    "def get_all_attention_maps(attn_type: str, layers: list[int], heads: list[int], row_tokens: list, col_tokens, max_sentence_len: int):\n",
    "    charts = []\n",
    "    for layer in layers:\n",
    "        rowCharts = []\n",
    "        for head in heads:\n",
    "            rowCharts.append(attn_map(attn_type, layer, head, row_tokens, col_tokens, max_sentence_len))\n",
    "        charts.append(alt.hconcat(*rowCharts))\n",
    "    return alt.vconcat(*charts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debad4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, encoder_input_tokens, decoder_input_tokens = load_next_batch()\n",
    "print(f'Source: {batch[\"src_text\"][0]}')\n",
    "print(f'Target: {batch[\"tgt_text\"][0]}')\n",
    "sentence_len = encoder_input_tokens.index(\"[PAD]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de8b55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [0, 1, 2]\n",
    "heads = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "# Encoder Self-Attention\n",
    "get_all_attention_maps(\"encoder\", layers, heads, encoder_input_tokens, encoder_input_tokens, min(20, sentence_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8586e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Self-Attention\n",
    "get_all_attention_maps(\"decoder\", layers, heads, decoder_input_tokens, decoder_input_tokens, min(20, sentence_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6151d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Self-Attention\n",
    "get_all_attention_maps(\"encoder-decoder\", layers, heads, encoder_input_tokens, decoder_input_tokens, min(20, sentence_len))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
